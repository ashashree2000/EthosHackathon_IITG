{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2329100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\Sandeep Roy\\3D Objects\\sentimental_analysis\\million news headlines dataset\\abcnews-date-text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9fb5cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snorkel in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (0.9.9)\n",
      "Requirement already satisfied: munkres>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (1.1.4)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (2.7.1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (1.4.2)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (1.21.5)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from snorkel) (2.11.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from snorkel) (1.0.2)\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from snorkel) (1.13.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->snorkel) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->snorkel) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->snorkel) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.2->snorkel) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.2->snorkel) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (61.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (1.33.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard>=2.9.1->snorkel) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard>=2.9.1->snorkel) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard>=2.9.1->snorkel) (1.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (2.27.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (3.19.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard>=2.9.1->snorkel) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (2.0.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->snorkel) (1.42.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (3.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.2.0->snorkel) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.33.0->snorkel) (0.4.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (3.4.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.1.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sandeep roy\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-23.1.4 gast-0.4.0 google-pasta-0.2.0 keras-2.11.0 libclang-14.0.6 opt-einsum-3.3.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\Sandeep Roy\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.[nltk_data] Downloading package stopwords to C:\\Users\\Sandeep\n",
      "[nltk_data]     Roy\\AppData\\Roaming\\nltk_data...\n",
      "\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#install needed packages\n",
    "!pip install snorkel\n",
    "!pip install textblob\n",
    "!pip install spacy\n",
    "!pip install tensorflow\n",
    "#import libraries and modules\n",
    "import io\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "#Snorkel\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import re\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function\n",
    "#NLP packages\n",
    "\n",
    "# import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "punc = string.punctuation\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Supervised learning\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "##Deep learning libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8936e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244184 entries, 0 to 1244183\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   text    1244184 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#conduct some data cleaning\n",
    "df = df.drop(['publish_date'], axis=1)\n",
    "df = df.rename(columns = {'headline_text': 'text'})\n",
    "df['text'] = df['text'].astype(str)\n",
    "#check the data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219e44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants to represent the class labels :positive, negative, and abstain\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "#define function which looks into the input words to represent a proper label\n",
    "def keyword_lookup(x, keywords, label):  \n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "#define function which assigns a correct label\n",
    "def make_keyword_lf(keywords, label=POSITIVE):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label))\n",
    "#resource: https://www.snorkel.org/use-cases/01-spam-tutorial#3-writing-more-labeling-functions\n",
    "#these two lists can be further extended \n",
    "\n",
    "\"\"\"positive news might contain the following words' \"\"\"\n",
    "keyword_positive = make_keyword_lf(keywords=['boosts', 'great', 'develops', 'promising', 'ambitious', 'delighted', 'record', 'win', 'breakthrough', 'recover', 'achievement', 'peace', 'party', 'hope', 'flourish', 'respect', 'partnership', 'champion', 'positive', 'happy', 'bright', 'confident', 'encouraged', 'perfect', 'complete', 'assured' ])\n",
    "\"\"\"negative news might contain the following words\"\"\"\n",
    "keyword_negative = make_keyword_lf(keywords=['war','solidiers', 'turmoil', 'injur','trouble', 'aggressive', 'killed', 'coup', 'evasion', 'strike', 'troops', 'dismisses', 'attacks', 'defeat', 'damage', 'dishonest', 'dead', 'fear', 'foul', 'fails', 'hostile', 'cuts', 'accusations', 'victims',  'death', 'unrest', 'fraud', 'dispute', 'destruction', 'battle', 'unhappy', 'bad', 'alarming', 'angry', 'anxious', 'dirty', 'pain', 'poison', 'unfair', 'unhealthy'\n",
    "                                              ], label=NEGATIVE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d085a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another set of labelling functions implemented using TextBlob: polarity and subjectivity\n",
    "# Subjectivity is the output that lies within [0,1] and refers to personal opinions and judgments. \n",
    "#set up a preprocessor function to determine polarity & subjectivity using textlob pretrained classifier \n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "#find polarity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return POSITIVE if x.polarity > 0.6 else ABSTAIN\n",
    "#find subjectivity \n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return POSITIVE if x.subjectivity >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ed5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1244184/1244184 [23:09<00:00, 895.24it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|                                                                                       | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.018]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=0.007]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=0.000]\n",
      " 55%|██████████████████████████████████████████▎                                  | 55/100 [00:00<00:00, 549.82epoch/s]INFO:root:[60 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[70 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[90 epochs]: TRAIN:[loss=0.000]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 704.06epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "# combining all the labeling functions and apply to dataset\n",
    "#combine all the labeling functions \n",
    "lfs = [keyword_positive, keyword_negative, textblob_polarity, textblob_subjectivity ]\n",
    "#apply the lfs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_snorkel = applier.apply(df=df)\n",
    "#apply the label model\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "#fit on the data\n",
    "label_model.fit(L_snorkel)\n",
    "#predict and create the labels\n",
    "df[\"label\"] = label_model.predict(L=L_snorkel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72a8c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    238018\n",
       "0    109987\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping unlabelled datapoints\n",
    "#Filtering out unlabeled data points\n",
    "df= df.loc[df.label.isin([0,1]), :]\n",
    "#find the label counts \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77f40a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "##store headlines and labels in respective lists\n",
    "text = list(df['text'])\n",
    "labels = list(df['label'])\n",
    "\n",
    "##sentences\n",
    "training_text = text[0:150000]\n",
    "testing_text = text[150000:]\n",
    "\n",
    "##labels\n",
    "training_labels = labels[0:150000]\n",
    "testing_labels = labels[150000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c06c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using word tokenizer from tensorflow.keras to create word encodings and sequences, then we pad the sequences\n",
    "#preprocess \n",
    "tokenizer = Tokenizer(num_words=10000, oov_token= \"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_text)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_text)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=120, padding='post', truncating='post')\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_text)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=120, padding='post', truncating='post')\n",
    "# convert lists into numpy arrays to make it work with TensorFlow \n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfdc6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                408       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we build embedding layer, add dense layer RelU, and sigmoid layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=120),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "##compile the model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a611808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4688/4688 - 19s - loss: 0.2514 - accuracy: 0.8873 - val_loss: 0.1027 - val_accuracy: 0.9638 - 19s/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "4688/4688 - 17s - loss: 0.0550 - accuracy: 0.9816 - val_loss: 0.0885 - val_accuracy: 0.9669 - 17s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "4688/4688 - 18s - loss: 0.0378 - accuracy: 0.9875 - val_loss: 0.0646 - val_accuracy: 0.9776 - 18s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "4688/4688 - 17s - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0629 - val_accuracy: 0.9790 - 17s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "4688/4688 - 17s - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0689 - val_accuracy: 0.9765 - 17s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "4688/4688 - 17s - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0661 - val_accuracy: 0.9786 - 17s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "4688/4688 - 18s - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0844 - val_accuracy: 0.9767 - 18s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "4688/4688 - 19s - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0779 - val_accuracy: 0.9760 - 19s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "4688/4688 - 18s - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0745 - val_accuracy: 0.9775 - 18s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "4688/4688 - 18s - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0736 - val_accuracy: 0.9789 - 18s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(training_padded, \n",
    "                    training_labels, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, testing_labels), \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b37c4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.97830856]]\n"
     ]
    }
   ],
   "source": [
    "new_headline = [\"Because of torrential rain, the city feels sad and gloomy\"]\n",
    "##prepare the sequences of the sentences in question\n",
    "# sequences = tokenizer.texts_to_sequences(new_headline)\n",
    "# padded_seqs = pad_sequences(sequences, maxlen=120, padding='post', truncating='post')\n",
    "# print(model.predict(padded_seqs))\n",
    "\n",
    "# doc = tokenizer.fit_on_texts(new_headline)\n",
    "# encoded_docs = tokenizer.texts_to_matrix(new_headline, mode='tfidf')\n",
    "# padded_docs = pad_sequences(encoded_docs, maxlen=120, padding='post', truncating='post')\n",
    "# print(model.predict(padded_docs))\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb8d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
